{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    txt.delete(0,'end')\n",
    "    res=\"\"\n",
    "    message.configure(text=res)\n",
    "def clear2():\n",
    "    txt2.delete(0,'end')\n",
    "    res=\"\"\n",
    "    message.configure(text=res)\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except(TypeError,ValueError):\n",
    "        pass\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8859cd762ca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msavetxt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "import csv\n",
    "from numpy import loadtxt\n",
    "import tkinter as tk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TakeImages():\n",
    "    cam=cv2.VideoCapture(0)\n",
    "    \n",
    "    a = txt2.get()\n",
    "    os.mkdir(\"known_faces/%s\"%(a))\n",
    "\n",
    "    while True:\n",
    "        _,frame = cam.read()\n",
    "\n",
    "        cv2.imshow(\"cam\",frame)\n",
    "\n",
    "        if cv2.waitKey(1)==ord('s'):\n",
    "            cv2.imwrite(\"known_faces/%s/%s.jpg\"%(a,a),frame)\n",
    "            res=\"Pic Taken\"\n",
    "            message.configure(text=res)\n",
    "            break\n",
    "        if cv2.waitKey(1)==27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainImages():\n",
    "    KNOWN_FACES='known_faces'\n",
    "    trainEncodings=[]\n",
    "    Names=[]\n",
    "    for name in os.listdir(KNOWN_FACES):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES}/{name}\"):\n",
    "            #image=face_recognition.load_image_file(f\"{KNOWN_FACES}/{name}/{filename}\")\n",
    "            image=cv2.imread(f\"{KNOWN_FACES}/{name}/{filename}\")\n",
    "            encoding = face_recognition.face_encodings(image)[0]\n",
    "            trainEncodings.append(encoding)\n",
    "            Names.append(name)\n",
    "    with open(\"encoding.pkl\",'wb') as f:\n",
    "        pickle.dump(trainEncodings,f)\n",
    "    \n",
    "    with open(\"names.pkl\",'wb') as f:\n",
    "        pickle.dump(Names,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track():\n",
    "    fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out=cv2.VideoWriter('output.mp4',fourcc,10.0,(640,480))\n",
    "    \n",
    "    with open('encoding.pkl','rb') as e:\n",
    "        trainEncodings=pickle.load(e)\n",
    "    with open('names.pkl','rb') as f:\n",
    "        Names=pickle.load(f)\n",
    "\n",
    "    cam = cv2.VideoCapture('drdo.mp4') \n",
    "    while True:\n",
    "        ret,testImage=cam.read()\n",
    "\n",
    "        facePositions=face_recognition.face_locations(testImage) \n",
    "        testEncodings=face_recognition.face_encodings(testImage,facePositions)\n",
    "\n",
    "        for (top,left,bottom,right),face_encoding in zip(facePositions,testEncodings):\n",
    "            name='Unknown'         \n",
    "            matches=face_recognition.compare_faces(trainEncodings,face_encoding)\n",
    "\n",
    "            if True in matches:\n",
    "                i=matches.index(True)\n",
    "                name=Names[i]\n",
    "\n",
    "            cv2.rectangle(testImage,(left,top),(right,bottom),(0,0,255),2)      \n",
    "            cv2.putText(testImage,name,(left-50,top-10),cv2.FONT_HERSHEY_SIMPLEX,.75,(0,255,0),1)\n",
    "            #Formula=\"INSERT INTO att (name,TIME,DATE) VALUES(%s,%s,%s)\"\n",
    "            #std=[(str(name),str(timeStamp),str(date)),]\n",
    "            #mycursor.executemany(Formula,std)\n",
    "            #mydb.commit() \n",
    "        cv2.imshow(\"Output\",testImage)\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from PIL  import ImageTk, Image\n",
    "import pickle\n",
    "def face():\n",
    "    window=tk.Tk()\n",
    "    window.title(\"Face Recognizer\")\n",
    "    window.geometry(\"{0}x{1}+0+0\".format(window.winfo_screenwidth(), window.winfo_screenheight()))\n",
    "    dialog_title=\"Quit\"\n",
    "    \n",
    "    bg =Image.open('pic.jpg')\n",
    "    new_image = bg.resize((window.winfo_screenwidth(), window.winfo_screenheight()))\n",
    "    photo = ImageTk.PhotoImage(new_image,master=window)\n",
    "    l1 = Label(window,image = photo)\n",
    "    l1.pack(pady=0,padx=0)\n",
    "\n",
    "    window.configure(background='black')\n",
    "    window.grid_rowconfigure(0,weight=1)\n",
    "    window.grid_columnconfigure(0,weight=1)\n",
    "    \n",
    "    flag =Image.open('indian_flag.jpeg')\n",
    "    resized_flag = flag.resize((350,150))\n",
    "    flag = ImageTk.PhotoImage(resized_flag,master = window)\n",
    "    l2 = Label(window,image = flag)\n",
    "    l2.place(x=40, y=40)\n",
    "    \n",
    "    emblem =Image.open('emblem.jpg')\n",
    "    resized_emblem = emblem.resize((150,250))\n",
    "    emblem = ImageTk.PhotoImage(resized_emblem,master = window)\n",
    "    l3 = Label(window,image = emblem)\n",
    "    l3.place(x=1250, y=40)\n",
    "\n",
    "    Label(window, text = \"BN SVL SYSTEM\",  width = 20, height = 2, fg =\"white\",  bg = \"black\", font = ('times', 45, ' bold ')).place(x = 450, y = 80) \n",
    "\n",
    "    lbl=tk.Label(window,text=\"Enter ID\",width=20,height=2,fg=\"white\",bg=\"black\",font=('times',15,'bold'))\n",
    "    lbl.place(x=250,y=260)\n",
    "    txt=tk.Entry(window,width=20,bg=\"black\", fg=\"white\", font=('times',25,'bold'))\n",
    "    txt.place(x=600,y=270)\n",
    "\n",
    "    lbl2=tk.Label(window,text=\"Enter Name\",width=20,height=2,fg=\"white\",bg=\"black\",font=('times',15,'bold'))\n",
    "    lbl2.place(x=250,y=360)\n",
    "    txt2=tk.Entry(window,width=20,bg=\"black\",fg='white',font=('times',25,'bold'))\n",
    "    txt2.place(x=600,y=370)\n",
    "\n",
    "    lbl3=tk.Label(window,text=\"Notification\",width=20,height=2,fg=\"white\",bg=\"black\",font=('times',15,'bold'))\n",
    "    lbl3.place(x=250,y=460)\n",
    "\n",
    "    message=tk.Label(window,text=\"\",bg=\"black\",fg=\"white\",width=30,height=2,activebackground=\"yellow\",font=('times',15,'bold'))\n",
    "    message.place(x=600,y=460)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def TakeImages():\n",
    "        cam=cv2.VideoCapture(0)\n",
    "\n",
    "        a = txt2.get()\n",
    "        os.mkdir(\"known_faces/%s\"%(a))\n",
    "\n",
    "        while True:\n",
    "            _,frame = cam.read()\n",
    "\n",
    "            cv2.imshow(\"cam\",frame)\n",
    "\n",
    "            if cv2.waitKey(1)==ord('s'):\n",
    "                cv2.imwrite(\"known_faces/%s/%s.jpg\"%(a,a),frame)\n",
    "                res=\"Pic Taken\"\n",
    "                message.configure(text=res)\n",
    "                break\n",
    "            if cv2.waitKey(1)==27:\n",
    "                break\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    def TrainImages():\n",
    "        KNOWN_FACES='known_faces'\n",
    "        trainEncodings=[]\n",
    "        Names=[]\n",
    "        for name in os.listdir(KNOWN_FACES):\n",
    "            for filename in os.listdir(f\"{KNOWN_FACES}/{name}\"):\n",
    "                #image=face_recognition.load_image_file(f\"{KNOWN_FACES}/{name}/{filename}\")\n",
    "                image=cv2.imread(f\"{KNOWN_FACES}/{name}/{filename}\")\n",
    "                encoding = face_recognition.face_encodings(image)[0]\n",
    "                trainEncodings.append(encoding)\n",
    "                Names.append(name)\n",
    "                res=\"Trained\"\n",
    "                message.configure(text=res)\n",
    "        with open(\"encoding.pkl\",'wb') as f:\n",
    "            pickle.dump(trainEncodings,f)\n",
    "\n",
    "        with open(\"names.pkl\",'wb') as f:\n",
    "            pickle.dump(Names,f)\n",
    "    \n",
    "    \n",
    "    def track():\n",
    "        res=\"Tracking\"\n",
    "        message.configure(text=res)\n",
    "        fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out=cv2.VideoWriter('output.mp4',fourcc,10.0,(640,480))\n",
    "\n",
    "        with open('encoding.pkl','rb') as e:\n",
    "            trainEncodings=pickle.load(e)\n",
    "        with open('names.pkl','rb') as f:\n",
    "            Names=pickle.load(f)\n",
    "\n",
    "        cam = cv2.VideoCapture(0) \n",
    "        while True:\n",
    "            ret,testImage=cam.read()\n",
    "\n",
    "            facePositions=face_recognition.face_locations(testImage) \n",
    "            testEncodings=face_recognition.face_encodings(testImage,facePositions)\n",
    "\n",
    "            for (top,left,bottom,right),face_encoding in zip(facePositions,testEncodings):\n",
    "                name='Unknown'         \n",
    "                matches=face_recognition.compare_faces(trainEncodings,face_encoding)\n",
    "\n",
    "                if True in matches:\n",
    "                    i=matches.index(True)\n",
    "                    name=Names[i]\n",
    "\n",
    "                cv2.rectangle(testImage,(left,top),(right,bottom),(0,0,255),2)      \n",
    "                cv2.putText(testImage,name,(left-50,top-10),cv2.FONT_HERSHEY_SIMPLEX,.75,(0,255,0),2)\n",
    "                #Formula=\"INSERT INTO att (name,TIME,DATE) VALUES(%s,%s,%s)\"\n",
    "                #std=[(str(name),str(timeStamp),str(date)),]\n",
    "                #mycursor.executemany(Formula,std)\n",
    "                #mydb.commit() \n",
    "            cv2.imshow(\"Output\",testImage)\n",
    "            if cv2.waitKey(1)==ord('q'):\n",
    "                break\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    takeImg=tk.Button(window,text=\" Take Images\",command=TakeImages,fg=\"white\",bg=\"black\",width=20,height=3, activebackground=\"red\",font=(\"times\",15,\"bold\"))\n",
    "    takeImg.place(x=250,y=560)\n",
    "\n",
    "    trainImg=tk.Button(window,text=\" Train \",command=TrainImages,fg=\"white\",bg=\"black\",width=20,height=3, activebackground=\"red\",font=(\"times\",15,\"bold\"))\n",
    "    trainImg.place(x=600,y=560)\n",
    "\n",
    "    trackImg=tk.Button(window,text=\"Track Images\",command=track,fg=\"white\",bg=\"black\",width=20,height=3, activebackground=\"red\",font=(\"times\",15,\"bold\"))\n",
    "    trackImg.place(x=950,y=560)\n",
    "\n",
    "    quitWindow=tk.Button(window,text=\"Quit\",command=window.destroy,fg=\"white\",bg=\"black\",width=30,height=4, activebackground=\"red\",font=(\"times\",15,\"bold\"))\n",
    "    quitWindow.place(x=600,y=680)\n",
    "\n",
    "\n",
    "    window.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pysound\n",
    "from pygame import mixer\n",
    "import time\n",
    "\n",
    "mixer.init()\n",
    "mixer.Sound('alarm4.wav')\n",
    "sound = mixer.Sound('alarm4.wav')\n",
    "\n",
    "def static():\n",
    "    mixer.init()\n",
    "    mixer.Sound('alarm4.wav')\n",
    "    sound = mixer.Sound('alarm4.wav')\n",
    "    # Video Capture \n",
    "    # capture = cv2.VideoCapture(0)\n",
    "    cap = cv2.VideoCapture('drdo.mp4')\n",
    "    total=0\n",
    "\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(50, 200, True)\n",
    "    fgbg2 = cv2.createBackgroundSubtractorMOG2(50, 200, True)\n",
    "\n",
    "    # Keeps track of what frame we're on\n",
    "    frameCount = 0\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "    crop = True\n",
    "    co = 1\n",
    "    r=(1,2,3,4)\n",
    "\n",
    "    while(True):\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if(crop==True and co==1):\n",
    "\n",
    "            r=cv2.selectROI(frame1)\n",
    "\n",
    "            co+=1\n",
    "            cv2.destroyWindow(\"ROI selector\")\n",
    "\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "            if cv2.contourArea(contour) < 900:\n",
    "                continue\n",
    "            cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        frameCount += 1\n",
    "\n",
    "        roi = frame2[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "\n",
    "        fgmask = fgbg.apply(roi)\n",
    "\n",
    "        count = np.count_nonzero(fgmask)\n",
    "\n",
    "        if (frameCount > 1 and count > 500):\n",
    "\n",
    "            cv2.putText(frame1, 'Static Object Movement',(10,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            sound.play()\n",
    "\n",
    "        cv2.imshow('Frame', frame1)\n",
    "        #cv2.imshow('mad', fgmask)\n",
    "        cv2.imshow(\"STATIC AREA\",roi)\n",
    "\n",
    "        frame1 = frame2\n",
    "        ret, frame2 = cap.read()\n",
    "\n",
    "        if k == ord('s'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time\n",
    "\n",
    "mixer.init()\n",
    "mixer.Sound('alarm4.wav')\n",
    "sound = mixer.Sound('alarm4.wav')\n",
    "\n",
    "def rest():\n",
    "    mixer.init()\n",
    "    mixer.Sound('alarm4.wav')\n",
    "    sound = mixer.Sound('alarm4.wav')\n",
    "    # Video Capture \n",
    "    #cap = cv2.VideoCapture(0)\n",
    "    cap = cv2.VideoCapture('drdo.mp4')\n",
    "    total=0\n",
    "\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(50, 200, True)\n",
    "    fgbg2 = cv2.createBackgroundSubtractorMOG2(50, 200, True)\n",
    "\n",
    "    # Keeps track of what frame we're on\n",
    "    frameCount = 0\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "    crop_rest = True\n",
    "    do = 1\n",
    "    r_rest=(1,2,3,4)\n",
    "\n",
    "    while(True):\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if (crop_rest==True and do==1):\n",
    "            r_rest = cv2.selectROI(frame1)\n",
    "            do+=1\n",
    "            cv2.destroyWindow(\"ROI selector\")\n",
    "\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "            if cv2.contourArea(contour) < 900:\n",
    "                continue\n",
    "            cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        frameCount += 1\n",
    "\n",
    "        roi_rest = frame2[int(r_rest[1]):int(r_rest[1]+r_rest[3]), int(r_rest[0]):int(r_rest[0]+r_rest[2])]\n",
    "\n",
    "        fgmask = fgbg.apply(roi_rest)\n",
    "\n",
    "        count = np.count_nonzero(fgmask)\n",
    "\n",
    "        if (frameCount > 1 and count > 500):\n",
    "\n",
    "            cv2.putText(frame1, 'RESTRICTED AREA ALERT',(10,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            sound.play()\n",
    "\n",
    "        cv2.imshow('Frame', frame1)\n",
    "        #cv2.imshow('mad', fgmask)\n",
    "        cv2.imshow(\"RESTRICTED AREA\",roi_rest)\n",
    "\n",
    "        frame1 = frame2\n",
    "        ret, frame2 = cap.read()\n",
    "\n",
    "        if k == ord('s'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def motion():\n",
    "    cap = cv2.VideoCapture('drdo.mp4')\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "    frame_height =int(cap.get( cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "\n",
    "    out = cv2.VideoWriter(\"output.avi\", fourcc, 5.0, (1280,720))\n",
    "\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "    #print(frame1.shape)\n",
    "    while cap.isOpened():\n",
    "\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        #diff = cv2.resize(diff, (0, 0), fx=0.50, fy=0.50)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "            if cv2.contourArea(contour) < 900:\n",
    "                continue\n",
    "            cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1, (0, 0, 255), 3)\n",
    "        #cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)\n",
    "        \n",
    "        image = cv2.resize(frame1, (1280,720))\n",
    "        out.write(image)\n",
    "        cv2.imshow(\"feed\", frame1)\n",
    "        frame1 = frame2\n",
    "        ret, frame2 = cap.read()\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from PIL  import ImageTk, Image\n",
    "\n",
    "root = tk.Tk()\n",
    "root.geometry(\"{0}x{1}+0+0\".format(root.winfo_screenwidth(), root.winfo_screenheight()))\n",
    "\n",
    "bgImage =Image.open('pic.jpg')\n",
    "new_image = bgImage.resize((root.winfo_screenwidth(), root.winfo_screenheight()))\n",
    "photo = ImageTk.PhotoImage(new_image)\n",
    "lbl = Label(root,image = photo)\n",
    "lbl.pack(pady=0,padx=0)\n",
    "\n",
    "flag =Image.open('indian_flag.jpeg')\n",
    "resized_flag = flag.resize((350,150))\n",
    "flag = ImageTk.PhotoImage(resized_flag)\n",
    "l2 = Label(root,image = flag)\n",
    "l2.place(x=40, y=40)\n",
    "\n",
    "emblem =Image.open('emblem.jpg')\n",
    "resized_emblem = emblem.resize((150,250))\n",
    "emblem = ImageTk.PhotoImage(resized_emblem)\n",
    "l3 = Label(root,image = emblem)\n",
    "l3.place(x=1250, y=40)\n",
    "\n",
    "Label(root, text = \"BN SVL SYSTEM\",  width = 20, height = 2, fg =\"white\",  bg = \"black\", font = ('times', 45, ' bold ')).place(x = 450, y = 120) \n",
    "Button(root, text =\"Face Recognition\",  command = lambda:face(), fg =\"white\", bg =\"black\",  width = 20, height = 3, activebackground = \"Red\",  font =('times', 15, ' bold ')).place(x = 100, y = 450) \n",
    "Button(root, text =\"Restricted Area\",  command = lambda:rest(), fg =\"white\", bg =\"black\",  width = 20, height = 3, activebackground = \"Red\",  font =('times', 15, ' bold ')).place(x = 450, y = 450) \n",
    "\n",
    "Button(root, text =\"Static Object Motion Detection\",  command = lambda:static(), fg =\"white\", bg =\"black\",  width = 24, height = 3, activebackground = \"Red\",  font =('times', 15, ' bold ')).place(x = 800, y = 450) \n",
    "\n",
    "Button(root, text =\"Multiple Cameras\",  command = lambda:motion(), fg =\"white\", bg =\"black\",  width = 20, height = 3, activebackground = \"Red\",  font =('times', 15, ' bold ')).place(x = 1200, y = 450) \n",
    "\n",
    "root.mainloop()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
